{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](http://ulcar.uml.edu/~iag/CS/GMDH-network.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each hemisphere of the brain, humans have a primary visual cortex, containing 140 million neurons, with tens of billions of connections between them. From this primary visual cortex, countless other cortexes process what the primary visual cortex saw, and do more image processing on their own way. At the  of all these layers, the final cortex outputs to the brain its understanding of what we are seeing. Consider the following images:\n",
    "\n",
    "![title](http://ufldl.stanford.edu/tutorial/images/Mnist_01.png)\n",
    "\n",
    "We can obviously see 0s at the top and 1s on the bottom. Now how does our brain identify this? Well we usually see defining patters in images that let us recognize what the object on the image is. If we see an oval then it's a 0. However, see how I just typed a 0 and it has a slash going through the middle? Well we also know that's a 0. How about 1s? We just have to look at a line with a downward tip at the top, and a horizontal line at the bottom. But is that always the case? In the images, the ones are just sticks. But maybe one person will draw a one with the shape described previously. Easily enough, when young, we learn to identify visually what 1s and 0s look like. \n",
    "\n",
    "Okay now try doing the same using algorithms on a computer. I'll wait... Think of all the special caveats and exceptions of the shape of a digit. Even simpler, just for 1s and 0s. Too many to count right? Now also know that you are working with images, so some people may write 1s small, others large, others side ways, others with sticks at the bottom, others without them, and so on... The problem for identifying if an image describes a 1 or a 0 just got really complicated. Now imagine the same thing but for all the digits. That's when you give up.\n",
    "\n",
    "However, we can use the neural network machine learning model for this task. Neural networks are modeled to function similar to our brain, with neurons recieving inputs, processing it and releasing an output based on this. After processing through several neurons, one final output is given by the network, which denotes the result of the network. Let's first load the images we will use on this notebook. They contain handwritten digits from 0 to 9, but on this one we will only use those that have a 1 or a 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8816, 785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41986</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41988</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41991</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "41986      0       0       0       0       0       0       0       0       0   \n",
       "41988      0       0       0       0       0       0       0       0       0   \n",
       "41991      1       0       0       0       0       0       0       0       0   \n",
       "41995      0       0       0       0       0       0       0       0       0   \n",
       "41996      1       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "41986       0    ...            0         0         0         0         0   \n",
       "41988       0    ...            0         0         0         0         0   \n",
       "41991       0    ...            0         0         0         0         0   \n",
       "41995       0    ...            0         0         0         0         0   \n",
       "41996       0    ...            0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "41986         0         0         0         0         0  \n",
       "41988         0         0         0         0         0  \n",
       "41991         0         0         0         0         0  \n",
       "41995         0         0         0         0         0  \n",
       "41996         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = pd.read_csv(\"digits.csv\")\n",
    "binary_digits = digits.loc[(digits.label == 0) | (digits.label == 1)]\n",
    "print(binary_digits.shape)\n",
    "binary_digits.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this dataframe, each row represents an image, and each column represents a pixel. The collection of all pixels of the image, represents the image itself. In this case, the images are made of 28 x 28 pixels, which in turn create 784 pixels (28 x 28). Let's separate each image from each label, so that we get a nice matrix of values. We can then use our trusty display function to display the image itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jununez\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       ..., \n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.get_dummies(binary_digits.label).values\n",
    "binary_digits.drop(\"label\",axis = 1, inplace = True)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xaaf6358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_width = image_height = 28\n",
    "def Display(img,width = 28,height = 28):\n",
    "    #Reshape the image into a 28x28 matrix.\n",
    "    one_image = img.reshape(width,height)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    #Create a grayscale pixel array of the pixel values.\n",
    "    plt.imshow(one_image, cmap=cm.binary)\n",
    "    plt.show()\n",
    "\n",
    "images = binary_digits.values\n",
    "Display(images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also convert the pixels of our images into floating point numbers, because we'll do some calculations later with them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images= images.astype(np.float64)\n",
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have this ready, let's talk about the key element of the neural network, the neurons.\n",
    "\n",
    "## Neurons\n",
    "\n",
    "As I mentioned previously, even in our brain, a neuron is a unit that takes several inputs, and based on some internal processing of the neuron, and relevant output is \"fired\" or not. In the case of our brain, these are electrical impulses that are transferred from neuron to neuron (neuroscientists please correct me if you read this ;) ). In programming it's a little bit different. Functions are made to output something, even when no return statement is specified, as they will output none if called with no return statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "def toproveapoint():\n",
    "    a = \"wow\"\n",
    "\n",
    "print(toproveapoint())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, we take numbers as inputs (which in turn represent something altogether), and output other numbers. So if a neuron were to not \"fire\" we would just output a 0 or something of that sort. Let's see an example with going to the movies on a night. You would consider several factors like: What movie is on premier, how many friends are available to go with you, and how much money do you have. So let's say that you don't like to go alone, but you don't mind that if there's a movie you really want to watch. So let's say that the movie factor has a weight of 2, and the friends factor a weight of 1. However, since without money you can't go to the movies, money takes the highest weight when making the decision. However, you are an avid moviegoer, so you are likely to say yes anyway. This is the bias of the decision factor. If you are keeping count then:\n",
    "\n",
    "$(1 * Friends to go with)  + (2 * MovieOnPremier) + (3 * HaveMoney) + (MoviegoerBias) = HowLikelyToGoMovies $\n",
    "\n",
    "Since we want a probability of how likely you are to go to the movies, you would want a function that outputs a number between 0 and 1. So let's say our previous equation is $\\sigma$. One function that would output a number between 1 and 0 is the sigmoid function.\n",
    "\n",
    "$S(\\sigma)  = \\dfrac{1}{1 + e^{-\\sigma}} $\n",
    "\n",
    "But hold on, this is looking familar. Like logistic regression!\n",
    "\n",
    "On neural networks, each neuron takes inputs and outputs, performs a dot product between the inputs, and weight + bias, then takes the result of that into an **activation function**, which then produces and output. An activation function does not necessarily have to be the sigmoid function. For example, if the result of $\\sigma$ is a really negative number, then the sigmoid function will output a really low number, which updates the parameters in a really small fashion. This way, the model is \"stuck\" training, because it's updating really slowly. One other activation function we can use is the hyperbolic tangent or **tanh**.\n",
    "\n",
    "$tanh(x) = \\dfrac{sinh(x)}{cosh(x)}$\n",
    "\n",
    "$tanh(x) = \\dfrac{e^x - e^{-x}}{e^x + e^{-x}}$\n",
    "\n",
    "$tanh(x) = \\dfrac{2}{1 + e^{-2x}} - 1$\n",
    "\n",
    "This function outputs values between -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIjIEAoGEREZQsEgIiJDKBhERGSI/w+LTUMBIAhEoQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xab051d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tanh(x):\n",
    "    denominator = 1 + np.exp(-2*x)\n",
    "    return (2)/denominator -1\n",
    "\n",
    "x = np.arange(-10,10,0.1)\n",
    "y = tanh(x)\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function outputs values near -1 when the input is  really negative, and values near 1 when the input is really positive and values near 0 when the output is near 0. Thus, to get the same output as the sigmoid function, we just need to positive outputs to 1 and negative outputs to 0. Simple stuff, however this whill help us later on when defining other concepts. So now we have the general structure of a neuron ready. To summarize, we apply a dot product between the input vector X and the weights w. We add the bias b to the result of that product. We then pass the product through an activation function, which produces an output y (Very similar process to the one from Logistic Regression).\n",
    "\n",
    "![title](https://blogs.cornell.edu/info2040/files/2015/09/VqOpE-1c4xc4y.jpg)\n",
    "\n",
    "Now that we have how the neurons of our neural network function, let's go over the architecture of a neural network.\n",
    "\n",
    "## Neural Network Architecture.\n",
    "\n",
    "A neural network is divided into several **layers**, where most neural networks have a minimum of 3 layers: an input layer, a hidden layer and an output layer. All neural networks have input and output layers, where the number of neurons is as big as the number of inputs in the layer, and the output layer is represented either as one neuron which outputs the final label, a layer of size c, where c is the number of unique labels. In between those there are hidden layers. They may sound mysterious, but they really mean that they are not either an input layer or an output layer. These hidden layers perform logistic regression on their own, and learn more complex features than their previous counterparts. Let's say that in the first layer, the neurons that are activated when friends to go with and have money. On the hidden layer, a neuron would learn a more complex feature from this, like having money + friends, but no good movies on primer + low bias. These neurons on the hidden layer would have their own weights and biases as well. This would go on and on , until we are at the final output layer, with its own weights and biases. The output of the network depends on this final calculation. The forward passing of the outputs of the outputs of the neural network makes it a **feedforward network**. This network will go from layer to layer, passing their outputs to the next layer, and then output the final class. \n",
    "\n",
    "![title](http://neuralnetworksanddeeplearning.com/images/tikz11.png)\n",
    "\n",
    "These regular layers that perform their activation function and regular dot product are called **layers**. Let's define their properties on a class (if you are a bit lost on classes, read notebook 1.7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    \n",
    "    def __init__(self, Weights,biases):\n",
    "        self.X = None #Define the X matrix input values later, since they aren't made when creating the layer.\n",
    "        self.y_prediction = None #The output of the layer.\n",
    "        self.Weights = Weights\n",
    "        self.biases = biases\n",
    "    \n",
    "    #Activation function.\n",
    "    def tanh(self,x):\n",
    "        denominator = 1 + np.exp(-2*x)\n",
    "        return (2)/denominator -1\n",
    "        \n",
    "    #Forward passing. Perform Dot product between input and weights. Then add biases. Finally, pass through activation.\n",
    "    def forward(self,X,output = False):\n",
    "        y_prediction = np.add(np.dot(X,self.Weights),self.biases)\n",
    "        y_prediction = self.tanh(y_prediction)\n",
    "        self.X = X\n",
    "        self.y_prediction = y_prediction\n",
    "        return y_prediction\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just so we are clear, we defined an activation function, the forward function and the initialization of layers. We can now use this class to define several layers on a network. Let's now create a neural network made with 3 layers: an input layer, a hidden layer and an output layer.\n",
    "\n",
    "- The input layer will take the 784 input pixels and return 100 outputs. \n",
    "\n",
    "- The hidden layer will take the 100 outputs of the input layer and return 10 outputs. \n",
    "\n",
    "- The output layer will the 10 outputs and return 2 outputs, representing the number of classes.\n",
    "\n",
    "Each layer will have a number of neurons equal to the number of inputs. Also, each layer's weights will have a dimension (Number of inputs,number of outputs) and a bias dimension of (number of outputs). These weights and biases will be initialized with random numbers. Let's see this in action now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 100)"
      ]
     },
     "execution_count": 1269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input layer\n",
    "np.random.seed(87)\n",
    "\n",
    "input_weight =np.random.randn(784,100)/100 #Input layer weights dimension 784 pixels 100 outputs.\n",
    "input_bias = np.random.randn(100)/100 #Input layer bias dimension\n",
    "input_layer = Layer(input_weight,input_bias)\n",
    "input_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 1270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hidden layer\n",
    "hidden_weight = np.random.randn(100,10)/100 #Hidden layer weights dimension 100 inputs 10 outputs.\n",
    "hidden_bias = np.random.randn(10)/100 #Hidden layer bias dimension.\n",
    "hidden_layer = Layer(hidden_weight,hidden_bias)\n",
    "hidden_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 1271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Output Layer\n",
    "output_weight = np.random.randn(10,2)/100 #Output layer weights dimension 10 inputs and 2 class output.\n",
    "output_bias = np.random.randn(2) /100\n",
    "output_layer = Layer(output_weight,output_bias)\n",
    "output_weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also define a cross entropy \"layer\" after the output layer. While not a layer in the network itself, it will be used to provide the final output of the model, and the loss of the prediction as well. This is done first by applying **softmax** normalization, to convert the output of our final layer into the probability that each index is the label at hand. For example, if after applying softmax, the value of the output layer is [0.491,0.509], then the final predicted value is 1, because the maximum value of the array is at index 1. However, having the output this way helps us model our error in a much better fashion, by just applying the difference between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Cross_Entropy_Layer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.cost_entropy = None\n",
    "        self.y_predict = None\n",
    "        self.y = None\n",
    "        \n",
    "    def softmax_normalization(self,x):\n",
    "        e = np.exp(x)\n",
    "        s = e.sum(axis=1)\n",
    "        s_reshape = np.repeat(s, x.shape[1]).reshape(x.shape)\n",
    "        return e/s_reshape\n",
    "    \n",
    "    \n",
    "    def forward(self,y_predict,y):\n",
    "        self.y_predict = self.softmax_normalization(y_predict)\n",
    "        self.y = y\n",
    "        \n",
    "        mult = np.multiply(y,np.log(self.y_predict))\n",
    "        self.cost_entropy = - np.sum(mult)\n",
    "        return self.y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost_entropy = Cross_Entropy_Layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined our layers, let's train the network by passing forward the data through the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xaf4e5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilites for each label : [[ 0.49968246  0.50031754]]\n",
      "Prediction = 1\n"
     ]
    }
   ],
   "source": [
    "test_image = images[0]\n",
    "\n",
    "input_pred = input_layer.forward(test_image)\n",
    "hidden_pred = hidden_layer.forward(input_pred)\n",
    "output_pred = output_layer.forward(hidden_pred).reshape(-1,2) #Reshape into a 2d array\n",
    "final_prediction = cost_entropy.forward(output_pred,labels)\n",
    "Display(test_image)\n",
    "print(\"Probabilites for each label : \" +str(final_prediction))\n",
    "print(\"Prediction = {}\".format(np.argmax(final_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model was 89.24682395644284%\n"
     ]
    }
   ],
   "source": [
    "def Score(images):\n",
    "    predictions = []\n",
    "    for image in images:\n",
    "        input_pred = input_layer.forward(image)\n",
    "        hidden_pred = hidden_layer.forward(input_pred)\n",
    "        output_pred = output_layer.forward(hidden_pred).reshape(-1,2)\n",
    "        final_prediction = cost_entropy.forward(output_pred,labels)\n",
    "        predictions.append(final_prediction.ravel())#Convert it into a 1D array\n",
    "    \n",
    "    real_values = np.argmax(labels,axis = 1)\n",
    "    predicted_values = np.argmax(np.asarray(predictions),axis = 1)\n",
    "    accuracy = np.sum(np.equal(real_values,predicted_values))/ labels.shape[0]\n",
    "    return accuracy * 100\n",
    "    \n",
    "print(\"Accuracy of model was {}%\".format(Score(images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is great, however the model is very volatile. If you don't believe me, just try changing the random seed! Remember that on previous models, to optimize them we would compare the predictions of the model with the actual output, and update the parameters based on Gradient Descent. However, two problems arise with this on Neural Networks:\n",
    "\n",
    "1. The only output that recieves feedback from the actual predictions is the final layer. Thus, the other layers don't know how right or wrong they are.\n",
    "\n",
    "2. Gradient Descent uses the final output to update the parameters. Neural Networks take a long time just to do one training round, and gradient descent would take too much time.\n",
    "\n",
    "To solve problem 2 we will implement **Stochastic Gradient Descent**. This is a variation of Gradient Descent where the parameters,in this case the weight and bias, are updated per training example, instead of waiting for the whole training procedure to be finished. In practice, batches of training examples are used instead of single training examples. To solve problem 1, we'll use the **Backpropagation** algorithm.\n",
    "\n",
    "## Backpropagation\n",
    "\n",
    "Backpropagation is based on the chain rule from differential Calculus. Remember that the gradient of a function is found by calculating the partial derivatives of the function. The chain rule states that the derivative of a composite function, or a function with a variable that depends on another variable, is the derivative of the second function, multiplied by the derivative of the first function and the second function:\n",
    "\n",
    "![title](https://wikimedia.org/api/rest_v1/media/math/render/svg/075ea30eb4897a37e57bd9ac7bd6a097a1f42167)\n",
    "\n",
    "Now what does this have to do with our network? Well the error of the final output layer is just one number. Each layer has different weights to update, and different dimensions. And thus the calculation of the gradient is different for each of them. However, the output of each layer is a function in itself. So to pass the error for the parameter in an equivalent way, and to calculate the gradient, we need to transform the error to the shape of the weights of each layer. Since the input of the next layer is dependent on the output of the layer previous layer, this makes the gradient of each layer, a function that depends on the layer before it, thus making it a composite function.\n",
    "\n",
    "![title](https://qph.ec.quoracdn.net/main-qimg-7bdfcff266211a74a31bfcdcc99c0087)\n",
    "\n",
    "\n",
    "To do all this, we need to modify our Linear Layer and Cross Entropy class to include backpropagation. This will take the error of the previous layer, and reshape it to the current layer by multiplying it by the weight of the layer. We need to calculate two errors:\n",
    "\n",
    "- The error of the activation function. This is calculated by taking the derivative of the activation function and multiplying it by the error of the previous layer. In this casE:\n",
    "\n",
    "    $ \\Delta a = tanh'(x) \\cdot \\delta = (1 - tanh^2(x)) \\cdot \\delta$\n",
    "    \n",
    "- The error of the weighted sum. This is calculated by multiplying the error of the activation function and multiplying it by the weight transpose vector of the current layer. This error is the one being sent to the next layer before it:\n",
    "\n",
    "    $ \\Delta y = \\Delta a \\cdot W^{t}_i $\n",
    "\n",
    "We also calculate the derivative of the Weight and Bias parameters. The derivative of the weights is the transpose of its input (in these cases it's the activation function of the layer previous to it during forward propagation) multiplied by the activation error. For the bias, it's the sum of the activation error. We repeat this procedure for all layers except the input layer, passing the error from the last layer, all the way to the second layer. To do this, we'll need to change our Linear Layer and Cross Entropy class to include the backpropagation function. For  regular layers, the backward procedure recieves the error of the previous layer, calculates the derivative of the activation function which was stored during the forward procedure, calculates the error of the activation function, and calculate the derivatives for the weight and bias.Then, we calculate the error of the weighted sum, which we will pass to the next layer. Finally, we call the Stochastic Gradient Descent procedure, which updates the weight and bias based on the Linear Regression parameter update, which is the learning rate divided by the number of examples multiplied by the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    \n",
    "    def __init__(self, Weights,biases,learning_rate = 0.001):\n",
    "        self.X = None #Define the X matrix input values later, since they aren't made when creating the layer.\n",
    "        self.y_prediction = None #The output of the layer.\n",
    "        self.activation = None\n",
    "        self.Weights = Weights\n",
    "        self.biases = biases\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dX = None #Error of the layer.\n",
    "        self.dW = None #Derivative of the weights.\n",
    "        self.db = None #Derivative of the bias.\n",
    "    \n",
    "    #Activation function.\n",
    "    def tanh(self,x):\n",
    "        denominator = 1 + np.exp(-2*x)\n",
    "        return (2)/denominator -1\n",
    "    \n",
    "    #Derivative of the activation function\n",
    "    def tanh_prime(self,x):\n",
    "        return 1 - x**2\n",
    "    \n",
    "    #Forward passing. Perform Dot product between input and weights. Then add biases. Finally, pass through activation.\n",
    "    def forward(self,X):\n",
    "        y_prediction = np.add(np.dot(X,self.Weights),self.biases)\n",
    "        self.activation = self.tanh(y_prediction)\n",
    "        self.X = X\n",
    "        return y_prediction\n",
    "    \n",
    "    #Backpropagation. dy means the error of the previous layer and dX is the error of the currenct layer.\n",
    "    def backward(self, dy):\n",
    "        activation_derivative = self.tanh_prime(self.activation)\n",
    "        activation_error = np.multiply(dy,activation_derivative)\n",
    "        self.dW = np.dot(self.X.T,activation_error)\n",
    "        self.db = np.sum(activation_error,axis = 0)\n",
    "        dX = np.dot(activation_error,self.Weights.T)\n",
    "        self.SGD()\n",
    "        return dX\n",
    "\n",
    "    \n",
    "    def SGD(self):\n",
    "        self.Weights -=  (self.learning_rate/self.X.shape[0]) * self.dW\n",
    "        self.biases  -=  (self.learning_rate/self.X.shape[0]) * self.db\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the cross entropy layer, the backward procedure just returns the difference between the prediction during the forward procedure and the ground truth of the labels. This is then passed to the previous layer in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Cross_Entropy_Layer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.cost_entropy = None\n",
    "        self.y_predict = None\n",
    "        self.y = None\n",
    "        \n",
    "    def softmax_normalization(self,x):\n",
    "        e = np.exp(x)\n",
    "        s = e.sum(axis=1)\n",
    "        s_reshape = np.repeat(s, x.shape[1]).reshape(x.shape)\n",
    "        return e/s_reshape\n",
    "    \n",
    "    \n",
    "    def forward(self,y_predict,y):\n",
    "        self.y_predict = self.softmax_normalization(y_predict)\n",
    "        self.y = y\n",
    "        \n",
    "        mult = np.multiply(y,np.log(self.y_predict))\n",
    "        self.cost_entropy = - np.sum(mult)\n",
    "        return self.y_predict\n",
    "    \n",
    "    def backward(self):\n",
    "        return self.y_predict - self.y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize the network once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_weight =np.random.randn(784,100)/100 #Input layer weights dimension 784 pixels 100 outputs.\n",
    "input_bias = np.random.randn(100)/100 #Input layer bias dimension\n",
    "input_layer = Layer(input_weight,input_bias)\n",
    "\n",
    "hidden_weight = np.random.randn(100,10)/100 #Hidden layer weights dimension 100 inputs 10 outputs.\n",
    "hidden_bias = np.random.randn(10)/100 #Hidden layer bias dimension.\n",
    "hidden_layer = Layer(hidden_weight,hidden_bias)\n",
    "\n",
    "output_weight = np.random.randn(10,2)/100 #Output layer weights dimension 10 inputs and 2 class output.\n",
    "output_bias = np.random.randn(2) /100\n",
    "output_layer = Layer(output_weight,output_bias)\n",
    "\n",
    "cost_entropy = Cross_Entropy_Layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, let's do a more advanced training procedure for the network. This time we will train the network for several epochs, just like we used to do on Gradient Boosting. We are also going to divide the images into **batches**. This way we only apply gradient descent once for each layer, on each batch. This is also called **Batch Gradient Descent**. On each epoch we will randomize the dataset so we get a different order of batches. Since SGD updates per batch, the order of the batches makes a difference on the parameter updates. On each batch we perform the forward and backward procedure, and we shuffle the batches on each epoch. For batch size we will use 100 images, but this depends on you. Without further ado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for epoch 0 : 47.311705989110706%\n",
      "Training epoch 1\n",
      "Training Accuracy for epoch 1 : 99.6483666061706%\n",
      "Training epoch 2\n",
      "Training Accuracy for epoch 2 : 99.72776769509983%\n",
      "Training epoch 3\n",
      "Training Accuracy for epoch 3 : 99.76179673321234%\n",
      "Training epoch 4\n",
      "Training Accuracy for epoch 4 : 99.79582577132487%\n",
      "Training epoch 5\n",
      "Training Accuracy for epoch 5 : 99.8185117967332%\n",
      "Training epoch 6\n",
      "Training Accuracy for epoch 6 : 99.8185117967332%\n",
      "Training epoch 7\n",
      "Training Accuracy for epoch 7 : 99.8185117967332%\n",
      "Training epoch 8\n",
      "Training Accuracy for epoch 8 : 99.8185117967332%\n",
      "Training epoch 9\n",
      "Training Accuracy for epoch 9 : 99.84119782214155%\n",
      "Training epoch 10\n",
      "Training Accuracy for epoch 10 : 99.84119782214155%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(None)\n",
    "batch_size = 100\n",
    "epochs = 10\n",
    "size = len(images)\n",
    "print(\"Training Accuracy for epoch {} : {}%\".format(0,Score(images)))\n",
    "for e in range(epochs):\n",
    "    print(\"Training epoch {}\".format(e+1))\n",
    "    indices = np.random.permutation(size)\n",
    "    X_random = images[indices]\n",
    "    y_random = labels[indices]\n",
    "\n",
    "    for i in range(size // batch_size):\n",
    "        image_batch = X_random[i * batch_size : (i + 1) * batch_size]\n",
    "        label_batch = y_random[i * batch_size : (i + 1) * batch_size]\n",
    "        \n",
    "        #Feed forward\n",
    "        input_forward  = input_layer.forward(image_batch)\n",
    "        hidden_forward = hidden_layer.forward(input_forward)\n",
    "        output_forward = output_layer.forward(hidden_forward)\n",
    "        final_prediction = cost_entropy.forward(output_forward,label_batch)\n",
    "        \n",
    "        #Feed backward\n",
    "        final_back = cost_entropy.backward()\n",
    "        output_back = output_layer.backward(final_back)\n",
    "        hidden_back = hidden_layer.backward(output_back)\n",
    "    \n",
    "    print(\"Training Accuracy for epoch {} : {}%\".format(e + 1,Score(images)))\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We now get an excellent training accuracy by optimizing the parameters of the network. Let's take a look at what happens inside the network for each layer by printing the input that goes through each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Image\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAA+1JREFUeJzt3TFO40AYgNFkEyHEoRAVXIMa0eYO9PScA9FRcRHuQAHI\newKsLFk7kb/32t94pvk0xSBnPQzDCuj5c+wNAMchfogSP0SJH6LED1HihyjxQ5T4IUr8ELWdeT3/\nTgjTW+/zkJMfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LE\nD1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQNfdPdDOz7+/v0flutxudbzab0fnD\nw8NBf8/xOPkhSvwQJX6IEj9EiR+ixA9R4oeo9TAMc64362KsVh8fH6Pzi4uLSd9/fn5+0Pv5lfU+\nDzn5IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9RPt3NQZ6enkbnd3d3M+2E\nf+XkhyjxQ5T4IUr8ECV+iBI/RIkfony6e+Gm/nT3zc3N6Pz5+fmg9/MrPt0N/Ez8ECV+iBI/RIkf\nosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1Hih6jtsTfA\ntDabzej8+vp6dP7y8vI/t8MJcfJDlPghSvwQJX6IEj9EiR+iXPUt3NnZ2ej89vZ2dO6qb7mc/BAl\nfogSP0SJH6LED1HihyjxQ5R7/oX7+voanb+9vc20E06Nkx+ixA9R4oco8UOU+CFK/BAlfohyz79w\nn5+fo/PHx8eZdsKpcfJDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1Hi\nhyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAl\nfogSP0SJH6K2x94A07q/vz/2FjhRTn6IEj9EiR+ixA9R4oco8UOU+CHKPf/Cvb+/H3sLnCgnP0SJ\nH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU\n+CFqPQzDnOvNuhir1evr6+j86upq0vdfXl4e9H5+Zb3PQ05+iBI/RIkfosQPUeKHKPFDlPghyj0/\nLI97fuBn4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFD\nlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfojazrzeXj8dDEzPyQ9R4oco8UOU+CFK/BAl\nfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9E/QV2z0Ve\nTxH21gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa8c8358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st Layer\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKScAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa3a10b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2nd layer\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHYAAAD8CAYAAACijFCvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAAsJJREFUeJzt3MGpwkAUQNEf0VJMBzZgTykpTWkx81tQcAi5nLMeHg9u\nZpPFLGOMP3ouRy/AHMJGCRslbJSwUcJGCRslbJSwUdcZQx+Px2l+Z+37fvQKX1nXdfnknBsbJWyU\nsFHCRgkbJWyUsFHCRgkbJWyUsFHCRgkbJWyUsFHCRgkbJWyUsFHCRgkbJWyUsFHCRgkbJWyUsFHC\nRgkbJWyUsFHCRgkbJWyUsFHCRgkbJWyUsFHCRgkbJWyUsFFT3lK83W4zxk6xruvRK0zhxkYJGyVs\nlLBRwkYJGyVslLBRwkYJGyVslLBRwkYJGyVslLBRwkYJGyVslLBRwkYJGyVslLBRwkYJGyVslLBR\nwkYJGyVslLBRwkYJGyVslLBRwkYJGyVslLBRwkYJG7WMMX4+9P1+/37oJGd7cm+MsXxyzo2NEjZK\n2Chho4SNEjZK2Chho4SNEjZK2Chho4SNEjZK2Chho4SNEjZK2Chho4SNEjZK2Chho4SNEjZK2Chh\no4SNEjZK2Chho4SNEjZK2Chho4SNEjZK2Chho4SNEjZK2KjrjKGXy3m+l9frdfQKU5ynAF8RNkrY\nKGGjhI0SNkrYKGGjhI0SNkrYKGGjhI0SNkrYKGGjhI0SNkrYKGGjhI0SNkrYKGGjhI0SNkrYKGGj\nhI0SNkrYKGGjhI0SNkrYKGGjhI0SNkrYKGGjhI0SNmrKk3vP53PG2Cm2bTt6ha/c7/ePzrmxUcJG\nCRslbJSwUcJGCRslbJSwUcJGCRslbJSwUcJGCRslbJSwUcJGCRslbJSwUcJGCRslbJSwUcJGCRsl\nbJSwUcJGCRslbJSwUcJGCRslbJSwUcJGCRslbJSwUcJGCRu1jDGO3oEJ3NgoYaOEjRI2StgoYaOE\njRI2StgoYaOEjRI2StgoYaOEjRI2StgoYaOEjRI2StgoYaOEjfoHAKAbngahyC0AAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa8a2cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd layer\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKgAAAD8CAYAAADjVO9VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAAtJJREFUeJzt2TEKAjAQRUFXvP+V1xMomCZPmOkDv3hsk9ndB1Q9bw+A\nbwRKmkBJEyhpAiVNoKQJlDSBkiZQ0l63Bxzy/fV/5uSRC0qaQEkTKGkCJU2gpAmUNIGSJlDSBEqa\nQEkTKGkCJU2gpAmUNIGSJlDSBEqaQEkTKGkCJU2gpAmUNIGSJlDSBEqaQEkTKGkCJU2gpAmUNIGS\nJlDSBEqaQEkTKGkCJU2gpAmUNIGSJlDSBEqaQEkTKGkCJU2gpAmUNIGSJlDSBEqaQEkTKGkCJU2g\npAmUNIGSJlDSBEqaQEkTKGkCJU2gpAmUNIGSJlDSBEqaQEkTKGkCJU2gpAmUNIGSJlDSBEqaQEkT\nKGkCJU2gpAmUNIGSJlDSBEqaQEkTKGkCJU2gpAmUNIGSJlDSBEqaQEkTKGkCJU2gpAmUNIGSJlDS\nBEqaQEkTKGkCJU2gpAmUNIGSJlDSBEqaQEkTKGkCJe11e8CJmbk9gR/t7tE7F5Q0gZImUNIESppA\nSRMoaQIlTaCkCZQ0gZImUNIESppASRMoaQIlTaCkCZQ0gZImUNIESppASRMoaQIlTaCkCZQ0gZIm\nUNIESppASRMoaQIlTaCkCZQ0gZImUNIESppASRMoaQIlTaCkCZQ0gZImUNIESppASRMoaQIlTaCk\nCZQ0gZImUNIESppASRMoaQIlTaCkCZQ0gZImUNIESppASRMoaQIlTaCkCZQ0gZImUNIESppASRMo\naQIlTaCkCZQ0gZImUNIESppASRMoaQIlTaCkCZQ0gZImUNIESppASRMoaQIlTaCkCZQ0gZImUNIE\nSppASRMoaQIlTaCkCZQ0gZImUNIESppASRMoaQIlTaCkCZQ0gZImUNIEStrs7u0N8JELSppASRMo\naQIlTaCkCZQ0gZImUNIESppASRMoaQIlTaCkCZQ0gZImUNIESppASRMoaQIlTaCkCZQ0gZL2BpL+\nC/XL7gzuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9a29a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def Display_Image_Net(index):\n",
    "    test = images[index]\n",
    "    print(\"Original Image\")\n",
    "    Display(test)\n",
    "    input_forward  = input_layer.forward(test)\n",
    "    print(\"1st Layer\")\n",
    "    Display(input_forward,width = 10,height = 10)\n",
    "    hidden_forward = hidden_layer.forward(input_forward)\n",
    "    print(\"2nd layer\")\n",
    "    Display(hidden_forward,width = 5,height = 2)\n",
    "    print(\"3rd layer\")\n",
    "    output_forward = output_layer.forward(hidden_forward)\n",
    "    Display(output_forward,width = 2,height = 1)\n",
    "    print(\"Prediction:\")\n",
    "    final_prediction = cost_entropy.forward(output_forward.reshape(-1,2),labels[index])\n",
    "    print(np.argmax(final_prediction))\n",
    "    \n",
    "Display_Image_Net(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the layers receive less and less pixels as we go along through the network. In the end we only recieve two pixels, a black one and a white one. The one in black represents the final label for the image. Since our network didn't get 100% accuracy, let's see which images it missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9a51668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nh1D/AKVwsfsFOQ4VAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa31dda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa7a29e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABhNJREFUeJzt3b9vTX8cx/HebxqJQSQGk0EljUlI091kQUgYxCCCwWwy\nEDGwCfoPMAlGSaWLGIqZmCRF7BbRiB+D+10YvvE973O1957b9vV4rO/e+/kMnvkMH+eeXr/fnwDy\n/DPuDQDjIX4IJX4IJX4IJX4IJX4IJX4IJX4IJX4INdnxev47IYxeb5A/cvJDKPFDKPFDKPFDKPFD\nKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFD\nKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFD\nKPFDKPFDKPFDqMlxbwDGYW5urpxfu3atnJ84caKcnz9/vpzv2bOnnHfByQ+hxA+hxA+hxA+hxA+h\nxA+hev1+v8v1Ol2Mte3Hjx/lfO/evSNb+8OHD+X827dvq/r+M2fOlPM7d+6s6vtb9Ab5Iyc/hBI/\nhBI/hBI/hBI/hBI/hBI/hPJIL6XXr1+X87dv35bzpaWlxtn8/Hz52Tdv3pTzUdq8eXM5v379ejmf\nnZ0d5nZGwskPocQPocQPocQPocQPocQPocQPodzzh1tcXCznR48eLeefPn0a5nbWjCtXrpTzCxcu\ndLST0XHyQyjxQyjxQyjxQyjxQyjxQyjxQyj3/BtA9Rvzbb+Nf/v27XK+Ue/xp6amyvmRI0c62sn4\nOPkhlPghlPghlPghlPghlPghlPghVK/f73e5XqeLbRSPHj0q5zdu3GicPX/+fNjbidD2vP7Nmzc7\n2smK9Ab5Iyc/hBI/hBI/hBI/hBI/hBI/hPJI7zqwsLBQzl3n/b/p6enG2cGDB8vPnj17dtjbWXOc\n/BBK/BBK/BBK/BBK/BBK/BBK/BDKPf8asLy8XM6XlpY62smf9u3bV85fvXrV0U7+1PZY7enTpxtn\n27ZtG/Z21h0nP4QSP4QSP4QSP4QSP4QSP4QSP4Ryz9+Bttdct/0099OnT4e5nf/Yv39/OZ+ZmSnn\nX758Kee7d+9unD1+/Lj87IEDB8r5jh07yrm7/JqTH0KJH0KJH0KJH0KJH0KJH0KJH0J5RXcH2n4D\n/u7duyNbe/v27eX8wYMH5bztmfn5+fm/3tNvU1NT5fz9+/cr/u5wXtENNBM/hBI/hBI/hBI/hBI/\nhBI/hPI8/4Cq59ZfvHhRfrbtufU2vV59bXvu3LnGWdsz7YcOHSrnX79+Ledtqrv8hYWFVX03q+Pk\nh1Dih1Dih1Dih1Dih1Dih1Cu+gb08OHDxll11TYM1aumJyYmJg4fPtw4O3bsWPnZnz9/rmhPv7X9\nfHZ1nVf9rDej5+SHUOKHUOKHUOKHUOKHUOKHUOKHUO75BzTK12Tv2rWrnM/NzZXzrVu3DnM7f+Xk\nyZPl3F3+2uXkh1Dih1Dih1Dih1Dih1Dih1Dih1Du+X+5detWOb93797I1l5eXi7nx48fH9nabS5d\nulTOr1692s1GGDonP4QSP4QSP4QSP4QSP4QSP4QSP4Ryz//Ly5cvx7b2x48fy/mTJ09Gtvbly5dX\nNZ+c9E9ovXLyQyjxQyjxQyjxQyjxQyjxQyj3NL88e/Zs3FtYsZ07dzbO2h5Fnp2dLeebNm1ayZZY\nB5z8EEr8EEr8EEr8EEr8EEr8EEr8EKrX7/e7XK/Txf7Gu3fvyvnMzEzj7PPnz6tau+0u/eLFi+X8\n1KlTjbPp6ekV7Yl1rTfIHzn5IZT4IZT4IZT4IZT4IZT4IZT4IZR7/gHdv3+/cfb9+/dVffeWLVvK\n+Thf0c265J4faCZ+CCV+CCV+CCV+CCV+CCV+COWeHzYe9/xAM/FDKPFDKPFDKPFDKPFDKPFDKPFD\nKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFD\nKPFDKPFDKPFDqMmO1xvo1cHA6Dn5IZT4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IZT4\nIZT4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IdS/63/TdgLcKgIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa457828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9R+q6w0YtoZ/nwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9a3db00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABsBJREFUeJzt3TGozf8fx/F7+elmILn6lSiJKxnERObbFUk3V6IMdA2U\noohFMhhkIF2LTDKwmVBXlmsxqCuFLAyikJu6JdTt/hf/wXDe97rn3sPvvh6P9XW/5/s1PH2Hj+O2\nj4+PtwF55vzpBwD+DPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDqH9afD//nBBmXvtkfsibH0KJH0KJ\nH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJ\nH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0K1+ld0w6QNDw+X++XLl8v90aNHDbczZ86U1/b395f7\nbODND6HED6HED6HED6HED6HED6HED6Gc8/PHPH36tNy7u7vLfWRkZMr3rv4NQFubc35gFhM/hBI/\nhBI/hBI/hBI/hBI/hHLOz4yqzvJ7enrKa5s5x5/I7t27Z+yz/yu8+SGU+CGU+CGU+CGU+CGU+CGU\noz6a8uTJk3Lv7e1tuH369Gm6H+cXO3fubLht2bJlRu/9X+DND6HED6HED6HED6HED6HED6HED6Ha\nx8fHW3m/lt6MiX39+rXcJzrH379/f7m/ffv2t59pujx+/LjhtmnTphY+Scu1T+aHvPkhlPghlPgh\nlPghlPghlPghlPghlO/zT9KzZ88abvPnzy+v7erqmu7HmbShoaFyv3jxYrnfvXu33Cf6s+/bt6/h\nduvWrfLaiWzcuLHcV65c2dTnz3be/BBK/BBK/BBK/BBK/BBK/BBK/BDKOf8kXb9+veG2Z8+e8tqZ\nPuc/d+5cw+3SpUvltaOjo+W+dOnSch8cHCz36s/e7Dn/kSNHyv3ff/9t6vNnO29+CCV+CCV+CCV+\nCCV+CCV+CCV+COWc/6cbN26U+9WrVxtuE53zf/nypdyvXbtW7mfPni33Hz9+lHtlxYoV5X7v3r1y\nX7duXbl///79t5/p/9avX1/uu3btmvJn480PscQPocQPocQPocQPocQPoRz1/TQ2Njbla/v6+sp9\nzpz679gPHz5M+d5tbW1ta9eubbj19/eX1x44cKDclyxZUu4T/YrvgwcPlntly5Yt5d7Z2Tnlz8ab\nH2KJH0KJH0KJH0KJH0KJH0KJH0K1j4+Pt/J+Lb3Z7xgZGSn3Y8eONdw+fvw43Y/zi56ennLfu3dv\nw23ZsmXT/Ti/OHHiRLlX/3X4RL9C+8GDB+W+atWqcg/WPpkf8uaHUOKHUOKHUOKHUOKHUOKHUOKH\nUL7P/9PixYvL/ebNmy16kr/LRN/Xf/HiRbm3tzc+cj558mR5rXP8meXND6HED6HED6HED6HED6HE\nD6HED6F8nz/ct2/fyv3UqVPlPjAwUO4dHR1TvjdT5vv8QGPih1Dih1Dih1Dih1Dih1Dih1C+zx9u\naGio3Cc6x59Ib29vU9czc7z5IZT4IZT4IZT4IZT4IZT4IZSjvnAPHz5s6vqFCxeW+/Hjx5v6fGaO\nNz+EEj+EEj+EEj+EEj+EEj+EEj+Ecs4fbnBwsKnrr1y5Uu6bN29u6vOZOd78EEr8EEr8EEr8EEr8\nEEr8EEr8EMo5/yx3/vz5cn/58mW5L1q0qNxXr17928/E38GbH0KJH0KJH0KJH0KJH0KJH0KJH0K1\nj4+Pt/J+Lb0ZbW3Lly8v93fv3pX7hg0byn14eLjcX79+3XCbO3duee3t27fL/c6dO+V+9OjRhtu2\nbdvKazs7O8v9L9c+mR/y5odQ4odQ4odQ4odQ4odQ4odQvtI7DU6fPl3uz58/b+rzt27dWu4dHR0N\nt8+fPzd17zdv3pT7jh07yr36yvC8efPKa1+9elXuXV1d5T46OtpwGxsbK69N4M0PocQPocQPocQP\nocQPocQPocQPoXyldxps37693O/fv9+iJ2m9OXPq90f11dju7u7y2p6ennLv6+sr9wULFpT7LOYr\nvUBj4odQ4odQ4odQ4odQ4odQ4odQzvmnwfv378t9YGCg3C9cuDCdj/Nb1qxZU+6HDh0q94nO0g8f\nPvzbz0TTnPMDjYkfQokfQokfQokfQokfQokfQjnnh9nHOT/QmPghlPghlPghlPghlPghlPghlPgh\nlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPgh\nlPghlPghlPgh1D8tvt+kfnUwMPO8+SGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU\n+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CHU/wB2wPcV5dCzLAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9bdc6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABW1JREFUeJzt3T1r1M0egOHN4bGKhYVa2AmCL4hYWSkKKthpae3XULsU\nIooIfgKxFCGdkEoLESzUSlAQbbUJiFjuaU5xmp3EvGzy5L6u9pd/dmC5mWJ2dhem0+kE6PnPTi8A\n2BnihyjxQ5T4IUr8ECV+iBI/RIkfosQPUf/M+fV8nBC238J6/sjOD1HihyjxQ5T4IUr8ECV+iBI/\nRIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1Hihyjx\nQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfoj6\nZ6cXANvlxo0bM2ffvn0bPvvhw4ctXs3uY+eHKPFDlPghSvwQJX6IEj9EZY76rl69Opz//v17OF9Z\nWZk5W1xc3NCa2JynT58O5y9fvpw5u3379lYv51/Hzg9R4oco8UOU+CFK/BAlfogSP0QtTKfTeb7e\nXF/s/42ud04mk8ny8vJw/uXLl5mzY8eObWhNjK312YujR48O53/+/Jk5+/Xr14bW9C+xsJ4/svND\nlPghSvwQJX6IEj9EiR+ixA9Rmfv8nz59Gs4PHz48nB88eHArl8M6LC0tDec/f/4czu/du7eVy9lz\n7PwQJX6IEj9EiR+ixA9R4oco8UNU5px/LTdv3hzODxw4MKeVdIy+I2EymUyePHkynK/1nty6deuv\n11Ri54co8UOU+CFK/BAlfogSP0SJH6Kc8//PyZMnd3oJOc+ePRvO1/re/gcPHgznhw4d+us1ldj5\nIUr8ECV+iBI/RIkfosQPUZmf6D579uxwvrKyMpw7NtqYd+/ezZydO3du+Oz+/fuH869fvw7n4ffM\nT3QDs4kfosQPUeKHKPFDlPghSvwQlbnSe/HixeE8fCa8rV6/fr3hZ+/cuTOce882x84PUeKHKPFD\nlPghSvwQJX6IEj9EZc75L1y4sNNL2JNWV1eH8/v372/4f/s69e1l54co8UOU+CFK/BAlfogSP0SJ\nH6Iy39vP9njz5s1wfv78+Zmza9euDZ9dXl4ezvft2zech/nefmA28UOU+CFK/BAlfogSP0SJH6Iy\n9/nZHo8ePRrOR58juXz58vBZ5/jby84PUeKHKPFDlPghSvwQJX6IcqWXTVlYGN8ePX369MzZ27dv\nh88uLi5uaE240gsMiB+ixA9R4oco8UOU+CFK/BDlSi9DDx8+3NTzJ06cmDlzjr+z7PwQJX6IEj9E\niR+ixA9R4oco8UOU+/wMHT9+fDhfXV0dzt+/fz9zduTIkQ2tiTW5zw/MJn6IEj9EiR+ixA9R4oco\n8UOU+/xxHz9+HM4/f/48nF+5cmU4d5a/e9n5IUr8ECV+iBI/RIkfosQPUY764paWlobztX6C+/Hj\nx1u5HObIzg9R4oco8UOU+CFK/BAlfogSP0Q559/jXr16NZw/f/58OL906dJwfurUqb9dEruEnR+i\nxA9R4oco8UOU+CFK/BAlfohyzr/HvXjxYlPPu6+/d9n5IUr8ECV+iBI/RIkfosQPUeKHKOf8e9z3\n79+H8+vXrw/nZ86c2crlsIvY+SFK/BAlfogSP0SJH6LED1Hihyjn/Hvcjx8/hvO7d+/OaSXsNnZ+\niBI/RIkfosQPUeKHKPFD1MJ0Op3n6831xSBqYT1/ZOeHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco\n8UOU+CFK/BAlfogSP0SJH6Lm/dXd67pnDGw/Oz9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LE\nD1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQ9V/p2ZqwhP2V0wAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xab7c198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa2398d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x99c1080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa211710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABUNJREFUeJzt3T9vjW8cwGHHvwgDm24ikkpMIpEQXoHFbBeRWLyCrmJi\nNxlpYpDYRLBY+grMEk1MhAiG85v9knOX9vRU+7mu9Xsezz345Dvc7elkOp3uA3r27/QBgJ0hfogS\nP0SJH6LED1HihyjxQ5T4IUr8EHVwwe/z44Sw/SZ/8iGbH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkf\nosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4\nIUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQdXCnD8DOevfu3XB+5cqV4fzQoUPD+Y8fP/76TCyG\nzQ9R4oco8UOU+CFK/BAlfogSP0S554979OjRcD6dTofzX79+DecPHz6cObt79+7wWbaXzQ9R4oco\n8UOU+CFK/BAlfohy1ceWbHQV+OTJk5mzgwfH//3Onz8/nF+9enU4Z8zmhyjxQ5T4IUr8ECV+iBI/\nRIkfoiYb3dPO2UJfxr59a2trw/m1a9eG80+fPs3zOH9laWlpOH/z5s1wvry8PM/j7CaTP/mQzQ9R\n4oco8UOU+CFK/BAlfogSP0T5ff497vHjx8P5Tt7jb2R9fX04//bt24JOsjfZ/BAlfogSP0SJH6LE\nD1HihyjxQ5R7/j1udXV1p4/AP8rmhyjxQ5T4IUr8ECV+iBI/RIkfotzz7wHPnz+fOfvy5csCT8Ju\nYvNDlPghSvwQJX6IEj9EiR+iXPXtAa9fv545+/79++IOwq5i80OU+CFK/BAlfogSP0SJH6LED1Hu\n+Rm6cOHCcH7r1q3h/Pbt2/M8DnNk80OU+CFK/BAlfogSP0SJH6LED1Hu+Rl6+/btcL5//3h/uOf/\nd9n8ECV+iBI/RIkfosQPUeKHKPFDlHv+uDt37gznR44cGc7v378/z+P85vr168P56dOnt+3dBTY/\nRIkfosQPUeKHKPFDlPghSvwQ5Z4/bqPv5T9w4MBwvra2Ns/j/ObMmTPD+YkTJ7bt3QU2P0SJH6LE\nD1HihyjxQ5T4IcpV3y7w/v374Xx1dXVBJ5mvyWQynB8/fnxBJ2my+SFK/BAlfogSP0SJH6LED1Hi\nhyj3/LvA169fh/MPHz4s6CTzdfLkyeF8ZWVlQSdpsvkhSvwQJX6IEj9EiR+ixA9R4oco9/wMvXz5\ncjh/9erVpv/te/fubfpZts7mhyjxQ5T4IUr8ECV+iBI/RIkfotzzxz179mw4P3z48HD++fPnTb/7\n1KlTm36WrbP5IUr8ECV+iBI/RIkfosQPUa76doFjx44N50tLSzNn6+vrw2dfvHixqTOx+9n8ECV+\niBI/RIkfosQPUeKHKPFDlHv+XeDs2bPD+Y0bN2bOHjx4MO/j/JXLly/PnC0vLy/wJPyfzQ9R4oco\n8UOU+CFK/BAlfogSP0S5598Dzp07N3O20Vdv//z5c0vvvnTp0nA++hPfR48e3dK72RqbH6LED1Hi\nhyjxQ5T4IUr8ECV+iHLPvwfcvHlz5uzjx4/DZ1dWVobzixcvDudPnz4dzt3l/7tsfogSP0SJH6LE\nD1HihyjxQ5T4IWoynU4X+b6FvgyiJn/yIZsfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco\n8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ELXoP9H9R18pDGw/mx+ixA9R4oco8UOU+CFK\n/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6I+g/kqoI9\nirvO8AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa7881d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTw5VAwkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9aa8c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABl9JREFUeJzt3T+MjHsfxuGZ17BCopMtNLshEgmN0BIkIkFBgk6jUmjF\nn4RCoVCIRiJCodCsSGRDKUgUCAXbWIl/rUIEwRJzijcned9ivrM7uzvL3tfV3vvM8zg5nzzFz6xm\nu91uAHn+M9cPAMwN8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UOoVp/v568TwuxrTuaHvPkhlPghlPgh\nlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPgh\nlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghlPghVGuuHwDmwtjY\nWLm/efOm3IeHh8t97dq1U36mfvPmh1Dih1Dih1Dih1Dih1Dih1Dih1DO+Yl09erVcj9//ny5L1u2\nrNw/ffo05WfqN29+CCV+CCV+CCV+CCV+CCV+COWojznz8ePHcl+yZEm5v3r1qtxXrVo15WearFbr\n70/Hmx9CiR9CiR9CiR9CiR9CiR9CiR9C/f2Hlcyq9+/fl/vz58/LfdeuXR23Z8+eldeePn263B8+\nfFjuL168KPfK4OBguY+Ojvb82X8Kb34IJX4IJX4IJX4IJX4IJX4IJX4I1Wy32/28X19vRnfv3r0r\n9x07dpT7+Ph4uY+MjHTc9u7dW167efPmcn/w4EG5b926teO2ZcuW8tpuf+4NGzaU+xxrTuaHvPkh\nlPghlPghlPghlPghlPghlPghlHP+ee7t27flvm3btnJ//fr1tO5ffS/+8ePH5bUvX74s9+3bt/f0\nTI1GozExMVHuCxcu7Pmz/wDO+YHOxA+hxA+hxA+hxA+hxA+hxA+h/N7+ee7atWvlPt1z/G5+//7d\n09ZoNBpr1qyZ6cfhf3jzQyjxQyjxQyjxQyjxQyjxQ6iYo74fP36U+8DAQJ+eZOZV/wz2vXv3ZvXe\nS5cuLffbt2933IaGhsprT5w40csjMUne/BBK/BBK/BBK/BBK/BBK/BBK/BAq5pz/1q1b5b5///4+\nPcnUPXr0qNyfPHnScfv69etMP87/WblyZblv3Lix43b//v3y2nPnzvX0TP+qfm14szmp3249r3nz\nQyjxQyjxQyjxQyjxQyjxQyjxQ6iYc/4/+Rz/27dv5b579+5y//DhQ8dt0aJF5bUHDhwo93379pX7\n+vXry71y586dcv/161fPn91oNBrHjh3ruLVaMf/rd+TND6HED6HED6HED6HED6HED6HED6EcdvZB\nt38z4ODBg+VeneM3Go3G4sWLO27Hjx8vrz116lS5dzM6Olrue/bs6bg9ffp0Wvc+evRouR85cmRa\nnz/fefNDKPFDKPFDKPFDKPFDKPFDKPFDKOf8fXD58uVyv3HjxrQ+//Dhwx23buf4nz9/LveTJ0+W\n+6VLl8p9YmKi3CtDQ0PlvnPnznJfsGBBz/dO4M0PocQPocQPocQPocQPocQPoRz19cHNmzdn9fOr\nr/RevHixvPbChQvlPj4+3tMzTcbq1avL/e7du+W+YsWKmXycON78EEr8EEr8EEr8EEr8EEr8EEr8\nEMo5/wz4+fNnuX///n1W73/27NlZ/fzpGBgY6Lh1+7qwc/zZ5c0PocQPocQPocQPocQPocQPocQP\noZrtdruf9+vrzfplbGys3NetW9enJ+m/4eHhcq/O8g8dOjTTj8N/NSfzQ978EEr8EEr8EEr8EEr8\nEEr8EEr8EMr3+cMNDg6W+/Xr18u9299hWL58+ZSfif7w5odQ4odQ4odQ4odQ4odQ4odQvtI7A7r9\nNxwZGSn3M2fOlPuXL1+m/Ez/2rRpU7lfuXKl3Fstp8F/IV/pBToTP4QSP4QSP4QSP4QSP4QSP4Ry\nzg/zj3N+oDPxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjx\nQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjx\nQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQ6hWn+/X7PP9gA68+SGU+CGU+CGU+CGU+CGU+CGU\n+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CHUP3IL3Wkl\nTXfaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa3de8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUP8D/LAH4X1PAJsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa7e4668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def Wrong_indexes(images):\n",
    "    predictions = []\n",
    "    for image in images:\n",
    "        input_pred = input_layer.forward(image)\n",
    "        hidden_pred = hidden_layer.forward(input_pred)\n",
    "        output_pred = output_layer.forward(hidden_pred).reshape(-1,2)\n",
    "        final_prediction = cost_entropy.forward(output_pred,labels)\n",
    "        predictions.append(final_prediction.ravel())#Convert it into a 1D array\n",
    "    \n",
    "    real_values = np.argmax(labels,axis = 1)\n",
    "    predicted_values = np.argmax(np.asarray(predictions),axis = 1)\n",
    "    wrong_values = np.logical_not(np.equal(real_values,predicted_values))\n",
    "    return np.argwhere(wrong_values)\n",
    "\n",
    "wrong_indexes = Wrong_indexes(images).ravel()\n",
    "for index in wrong_indexes:\n",
    "    Display(images[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, these images are the weirdest out of the bunch, so it's no wonder they could get misclassified. So hopefully, by now you have an intuition about how neural networks work, and how they are optimized. In the next notebook we are going to see more tricks with neural networks, and classify more than two digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
