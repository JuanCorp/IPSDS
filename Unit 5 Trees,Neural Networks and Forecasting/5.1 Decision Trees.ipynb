{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](https://upload.wikimedia.org/wikipedia/commons/f/f3/CART_tree_titanic_survivors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As humans, a lot of times we make decisions based on some circumstances. For example, let's try to imagine the act of eating. We first ask ourselves:\n",
    "\n",
    "    Am I hungry? If no don't eat anything else continue.\n",
    "    Is there food in the kitchen? If yes eat that food, else continue.\n",
    "    Are there enough ingredients to prepare some food? If yes prepare the food and eat it, else continue\n",
    "    Do I have money to order food? If yes order food else die of hunger.\n",
    "    \n",
    "So you may see them as a chain of ifs, which model the whole path towards a final decision, by answering a lot of yes or no questions. This is called a **decision tree**.\n",
    "\n",
    "Decision Trees are a versatile, powerful and simple  prediction method, that are still widely used today, or in conjunction with other ML algorithms. The process and end result of the model is fairly easy to understand, even for those that aren't very technical or knowledgable of the problem or the method itself. And they are used in conjunction to other ML algorithms that we'll see later on.\n",
    "\n",
    "On this noteboook, we'll focus on a type of decision tree called **Classification and Regression Tree** or CART trees. These trees perform a classification or regression task based on given input data. This tree is similar to binary trees from data structures, where each node of a tree has zero,one or two \"children\" or decision results. Let's first load the Human Resources dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>dept</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.38             0.53               2                   157   \n",
       "1                0.80             0.86               5                   262   \n",
       "2                0.11             0.88               7                   272   \n",
       "3                0.72             0.87               5                   223   \n",
       "4                0.37             0.52               2                   159   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years   dept  \\\n",
       "0                   3              0     1                      0  sales   \n",
       "1                   6              0     1                      0  sales   \n",
       "2                   4              0     1                      0  sales   \n",
       "3                   5              0     1                      0  sales   \n",
       "4                   3              0     1                      0  sales   \n",
       "\n",
       "   salary  \n",
       "0     low  \n",
       "1  medium  \n",
       "2  medium  \n",
       "3     low  \n",
       "4     low  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HR = pd.read_csv(\"HR_comma_sep.csv\")\n",
    "HR.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains information of employees for some random company. It contains information like the last evaluation score, satisfaction level, promotions, average monthly hours, salary, etc; and the target variable, if the employee left the company or not. Right off the bat we can make some questions and assumptions about determining if  an employee left or not.\n",
    "\n",
    "    Where they overworked and/or underpaid?\n",
    "    Are they underperforming? \n",
    "    Are they unsatisfied with the company?\n",
    "    Have they spent a long time with the company without getting promoted?\n",
    "    \n",
    "\n",
    "Maybe a combination of these factors can give us a better probability of determining if an employee left or not.\n",
    "\n",
    "\n",
    "## 1. Gini\n",
    "\n",
    "So how do CART models work?\n",
    "\n",
    "Well first, an input variable and a target variable are given, for example the time spent on the company and if the employee left or not. Then, a split is made based on the input variable, dividing them into two groups. After this, the splits are evaluated to determine which one optimized the model best. To determine this we calculate the **Gini score**, which gives an idea of how good a split is. A perfect Gini score is one which completely separates both target classes ( if there are only two target classes like in binary classification) is 0, while one that separates them by 50/50 of each class in each split and has no impact on actually separing the data has a gini score of 1. \n",
    "\n",
    "To calculate it we first have to calculate the proportion of the target classes on both splits. \n",
    "\n",
    "$Proportion = \\dfrac{count(class)}{(count(grouprows))}$ \n",
    "\n",
    "Let's get the proportion for those that left the company, based on number of years they have spent on the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_years = HR.time_spend_company.median()\n",
    "median_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5312, 10)\n",
      "(9687, 10)\n"
     ]
    }
   ],
   "source": [
    "more_than_3 = HR.loc[HR.time_spend_company > median_years]\n",
    "less_than_3 = HR.loc[HR.time_spend_company <= median_years]\n",
    "print(more_than_3.shape)\n",
    "print(less_than_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are a lot more employees with less than three years than the ones with more than 3 years. Let's now calculate the proportions for both the ones who left and the ones who didn't, for those that have more than 3 years or 3 years or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than 3 years and left: 0.363704819277\n",
      "More than 3 years and stayed: 0.636295180723\n",
      "3 years or less and left: 0.169195829462\n",
      "3 years or more and stayed: 0.830804170538\n"
     ]
    }
   ],
   "source": [
    "def calc_Prop(class_count,count_rows):\n",
    "    return (class_count/count_rows)[-1]\n",
    "more_than_3_left = calc_Prop(more_than_3.loc[more_than_3.left == 1].count(),more_than_3.count())\n",
    "more_than_3_stayed = calc_Prop(more_than_3.loc[more_than_3.left == 0].count(),more_than_3.count())\n",
    "less_than_3_left = calc_Prop(less_than_3.loc[less_than_3.left == 1].count(),less_than_3.count())\n",
    "less_than_3_stayed = calc_Prop(less_than_3.loc[less_than_3.left == 0].count(),less_than_3.count())\n",
    "\n",
    "print(\"More than 3 years and left: \" + str(more_than_3_left))\n",
    "print(\"More than 3 years and stayed: \" + str(more_than_3_stayed))\n",
    "print(\"3 years or less and left: \" + str(less_than_3_left))\n",
    "print(\"3 years or more and stayed: \" + str(less_than_3_stayed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gini index is then calculated as follows:\n",
    "\n",
    "$Gini = \\sum Proportion * (1 - Proportion)$\n",
    "\n",
    "In our example, the gini index for the years on company is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.743984448933\n"
     ]
    }
   ],
   "source": [
    "def ComputeGini(proportions):\n",
    "    return sum([(prop * (1 - prop)) for prop in proportions])\n",
    "\n",
    "print(ComputeGini([more_than_3_left,more_than_3_stayed,less_than_3_left,less_than_3_stayed]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in the end, splitting by the median number of years wasn't that good of a split. Let's create a function that computes all these steps more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7439844489329797\n"
     ]
    }
   ],
   "source": [
    "def Gini(groups,class_values=[1,0],target_name = \"left\"):\n",
    "    gini = 0.0\n",
    "    for value in class_values:\n",
    "        for group in groups:\n",
    "            group_size = group.shape[0]\n",
    "            split = group.loc[group[target_name] == value]\n",
    "            split_size = split.shape[0]\n",
    "            if split_size > 0:\n",
    "                proportion = split_size / group_size\n",
    "                gini += proportion * (1 - proportion)\n",
    "    return gini\n",
    "\n",
    "print(Gini([HR.loc[HR.time_spend_company > median_years],HR.loc[HR.time_spend_company <= median_years]],[1,0],\"left\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's experiment with different values of years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 years 0.3627984870747277\n",
      "Split 2 years 0.4515623350408856\n",
      "Split 4 years 0.7981143203281653\n",
      "Split 5 years 0.6429470010167895\n"
     ]
    }
   ],
   "source": [
    "print(\"Split 1 years \" + str(Gini([HR.loc[HR.time_spend_company > 1],HR.loc[HR.time_spend_company <= 1]],[1,0],\"left\")))\n",
    "print(\"Split 2 years \" + str(Gini([HR.loc[HR.time_spend_company > 2],HR.loc[HR.time_spend_company <= 2]],[1,0],\"left\")))\n",
    "print(\"Split 4 years \" + str(Gini([HR.loc[HR.time_spend_company > 4],HR.loc[HR.time_spend_company <= 4]],[1,0],\"left\")))\n",
    "print(\"Split 5 years \" + str(Gini([HR.loc[HR.time_spend_company > 5],HR.loc[HR.time_spend_company <= 5]],[1,0],\"left\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also experiment with another variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split low salary 0.7153542922751005\n",
      "Split medium salary 0.7133050676097072\n",
      "Split high salary 0.5022896051397686\n"
     ]
    }
   ],
   "source": [
    "print(\"Split low salary \" + str(Gini([HR.loc[HR.salary == \"low\"],HR.loc[HR.salary != \"low\"]],[1,0],\"left\")))\n",
    "print(\"Split medium salary \" + str(Gini([HR.loc[HR.salary == \"medium\"],HR.loc[HR.salary != \"medium\"]],[1,0],\"left\")))\n",
    "print(\"Split high salary \" + str(Gini([HR.loc[HR.salary == \"high\"],HR.loc[HR.salary != \"high\"]],[1,0],\"left\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a compound experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split low salary 3 years 0.830374825997142\n",
      "Split low salary 2 year 0.4953205321386966\n",
      "Split medium salary 3 years 0.675601829840803\n",
      "Split medium salary 2 year 0.42338841464891047\n",
      "Split high salary 3 years 0.2643282469015171\n",
      "Split high salary 2 year 0.16017314032344593\n"
     ]
    }
   ],
   "source": [
    "low_salary = HR.loc[HR.salary == \"low\"]\n",
    "medium_salary = HR.loc[HR.salary == \"medium\"]\n",
    "high_salary = HR.loc[HR.salary == \"high\"]\n",
    "\n",
    "print(\"Split low salary 3 years \" + str(Gini([low_salary.loc[low_salary.time_spend_company > 3],\n",
    "                                             low_salary.loc[low_salary.time_spend_company <= 3]],[1,0],\"left\")))\n",
    "print(\"Split low salary 2 year \" + str(Gini([low_salary.loc[low_salary.time_spend_company > 2],\n",
    "                                             low_salary.loc[low_salary.time_spend_company <= 2]],[1,0],\"left\")))\n",
    "\n",
    "print(\"Split medium salary 3 years \" + str(Gini([medium_salary.loc[medium_salary.time_spend_company > 3],\n",
    "                                             medium_salary.loc[medium_salary.time_spend_company <= 3]],[1,0],\"left\")))\n",
    "\n",
    "print(\"Split medium salary 2 year \" + str(Gini([medium_salary.loc[medium_salary.time_spend_company > 2],\n",
    "                                             medium_salary.loc[medium_salary.time_spend_company <= 2]],[1,0],\"left\")))\n",
    "\n",
    "print(\"Split high salary 3 years \" + str(Gini([high_salary.loc[high_salary.time_spend_company > 3],\n",
    "                                             high_salary.loc[high_salary.time_spend_company <= 3]],[1,0],\"left\")))\n",
    "\n",
    "print(\"Split high salary 2 year \" + str(Gini([high_salary.loc[high_salary.time_spend_company > 2],\n",
    "                                             high_salary.loc[high_salary.time_spend_company <= 2]],[1,0],\"left\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we found a very good split for those that have a high salary and splitted at 2 years on the company. However, manually creating these splits is a tedious process. So let's create a function that iteratively creates a list of splits.\n",
    "\n",
    "## 2 Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Create_Split(data,split_column):\n",
    "    splits = []\n",
    "    if data[split_column].dtype == object or len(data[split_column].unique()) == 2:\n",
    "        #It's either a categorical column or a binary column.\n",
    "        values = data[split_column].unique()\n",
    "        if len(values == 2):\n",
    "            values = [values[0]]\n",
    "        for value in values:\n",
    "            left_split = data.loc[data[split_column] == value]\n",
    "            right_split = data.loc[data[split_column]!= value]\n",
    "            split_name = split_column + \" = \" + str(value)\n",
    "            splits.append([left_split,right_split,split_name])\n",
    "    else:\n",
    "        #It's a numerical column.\n",
    "        summary = data[split_column].describe()\n",
    "        values = np.asarray([summary[\"25%\"],summary[\"50%\"],summary[\"75%\"]])\n",
    "        #Make sure they are unique splits.\n",
    "        for value in np.unique(values):\n",
    "            left_split = data.loc[data[split_column] <= value]\n",
    "            right_split = data.loc[data[split_column] > value]\n",
    "            split_name = split_column + \" <= \" + str(value)\n",
    "            splits.append([left_split,right_split,split_name])\n",
    "    \n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_spend_company <= 3.0\n",
      "time_spend_company <= 4.0\n"
     ]
    }
   ],
   "source": [
    "year_splits = Create_Split(HR,\"time_spend_company\")\n",
    "#Print all the split names.\n",
    "for split in year_splits:\n",
    "    print(split[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see which column gives us the best singular split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Get_Best_Column_Split(data,target=\"left\",verbose = False):\n",
    "    temp = data.drop(target, axis = 1).copy()\n",
    "    best_gini = 1\n",
    "    best_split_condition = \"\"\n",
    "    best_split = {}\n",
    "    for column in temp.columns:\n",
    "        column_splits = Create_Split(data,column)\n",
    "        for split in column_splits:\n",
    "            \n",
    "            split_gini = Gini(split[0:2])\n",
    "            if verbose:\n",
    "                print(\"Splitting : \" + split[2] + \" Gini : \" + str(split_gini))\n",
    "            if split_gini < best_gini:\n",
    "                best_gini = split_gini\n",
    "                best_split_condition = split[2]\n",
    "                best_split[\"left\"] = split[0].drop(column,axis = 1)\n",
    "                best_split[\"right\"] = split[1].drop(column, axis = 1)\n",
    "                best_split[\"condition\"] = best_split_condition\n",
    "                \n",
    "    if verbose:\n",
    "        print(\"Best split: \" + best_split_condition + \" best Gini: \" + str(best_gini))\n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting : satisfaction_level <= 0.44 Gini : 0.6842218273867912\n",
      "Splitting : satisfaction_level <= 0.64 Gini : 0.6767195791231189\n",
      "Splitting : satisfaction_level <= 0.82 Gini : 0.6148138363301998\n",
      "Splitting : last_evaluation <= 0.56 Gini : 0.7758772040261261\n",
      "Splitting : last_evaluation <= 0.72 Gini : 0.7249095845147965\n",
      "Splitting : last_evaluation <= 0.87 Gini : 0.7678089292997319\n",
      "Splitting : number_project <= 3.0 Gini : 0.7289819499966351\n",
      "Splitting : number_project <= 4.0 Gini : 0.7698458241123651\n",
      "Splitting : number_project <= 5.0 Gini : 0.777638157339555\n",
      "Splitting : average_montly_hours <= 156.0 Gini : 0.7765419804049951\n",
      "Splitting : average_montly_hours <= 200.0 Gini : 0.7244178845497011\n",
      "Splitting : average_montly_hours <= 245.0 Gini : 0.7805322047899803\n",
      "Splitting : time_spend_company <= 3.0 Gini : 0.7439844489329797\n",
      "Splitting : time_spend_company <= 4.0 Gini : 0.7981143203281653\n",
      "Splitting : Work_accident = 0 Gini : 0.5333904902485388\n",
      "Splitting : promotion_last_5years = 0 Gini : 0.4788598302327364\n",
      "Splitting : dept = sales Gini : 0.72992688164157\n",
      "Splitting : salary = low Gini : 0.7153542922751005\n",
      "Best split: promotion_last_5years = 0 best Gini: 0.4788598302327364\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>dept</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.51</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.59</td>\n",
       "      <td>4</td>\n",
       "      <td>139</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>management</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.46</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.79</td>\n",
       "      <td>6</td>\n",
       "      <td>292</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>technical</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2</td>\n",
       "      <td>154</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>support</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     satisfaction_level  last_evaluation  number_project  \\\n",
       "18                 0.45             0.51               2   \n",
       "82                 0.79             0.59               4   \n",
       "171                0.41             0.46               2   \n",
       "287                0.11             0.79               6   \n",
       "584                0.41             0.56               2   \n",
       "\n",
       "     average_montly_hours  time_spend_company  Work_accident  left  \\\n",
       "18                    160                   3              1     1   \n",
       "82                    139                   3              0     1   \n",
       "171                   160                   3              0     1   \n",
       "287                   292                   4              0     1   \n",
       "584                   154                   3              0     1   \n",
       "\n",
       "           dept  salary  \n",
       "18        sales     low  \n",
       "82   management     low  \n",
       "171       sales     low  \n",
       "287   technical     low  \n",
       "584     support  medium  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Best_Split = Get_Best_Column_Split(HR,\"left\",verbose = True)\n",
    "Best_Split[\"right\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the column that helps us distinguish best if an employee has left the company or not is if they had a promotion in the last 5 years, based on its lowest gini score. This also makes sense that if an employee hasn't received a promotion they may feel disgruntled and end up leaving the office. However, this singular value is not enough to give us a good accuracy for prediction. If we combine a sequence of predictions, we can have a way better shot at dividing those who left and those who didn't. With splitting and calculating gini out of the way, we can proceed to actually building the **decision tree**.\n",
    "\n",
    "## 3. Creating a Decision Tree\n",
    "\n",
    "To build a tree we must make sure of the following things:\n",
    "\n",
    "- The tree must have final nodes which don't split anymore.\n",
    "- The tree must recursively find splits on itself.\n",
    "- A split must have a minimum number of examples per split and a maximum number of splits. \n",
    "\n",
    "Let's go step by step, and first establish when a node isn't allowed to split anymore. To do this we define to variables:\n",
    "\n",
    "- Maximum depth: If a route has reached the maximum depth, the tree isn't allowed to split anymore.\n",
    "- Minimum split size: The minimum number of rows that a split must contain.\n",
    "\n",
    "Let's first define how the predictions are made in the terminal node. This is done by selecting the most common value of all the possible values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def terminal_node(group,target=\"left\"):\n",
    "    outcomes = group[target].value_counts()\n",
    "    return outcomes.index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we proceed to creating the tree. This is done by calling getting the best column split over and over again while making sure that we don't surpass the max depth threshold, and that we are only splitting on nodes with enough values. This is done using a **recursive** function, a type of function that calls itself until it is stopped by a certain condition. In our case, it's when we have reached the max depth, or are unable to split anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Split_Tree(split,cur_depth,min_size,max_depth=3,target = \"left\",verbose = False):\n",
    "    left,right = split[\"left\"],split[\"right\"]\n",
    "    #In case our depth is too large.\n",
    "    del split[\"left\"]\n",
    "    del split[\"right\"]\n",
    "    \n",
    "    \n",
    "    if  not left.any or  not right.any:\n",
    "        split[\"left\"] = split[\"right\"] = terminal_node((left + right))\n",
    "        return\n",
    "    if cur_depth == max_depth:\n",
    "        split[\"left\"], split[\"right\"] = terminal_node(left), terminal_node(right)\n",
    "        return\n",
    "    #Calculate left\n",
    "    if len(left) <= min_size:\n",
    "        split[\"left\"] = terminal_node(left)\n",
    "    else:\n",
    "        split[\"left\"] = Get_Best_Column_Split(left,verbose = verbose)\n",
    "        Split_Tree(split[\"left\"],cur_depth + 1,min_size=min_size,verbose = verbose)\n",
    "    \n",
    "    #Calculate right\n",
    "    if len(right) <= min_size:\n",
    "        split[\"right\"] = terminal_node(right)\n",
    "    else:\n",
    "        split[\"right\"] = Get_Best_Column_Split(right,verbose = verbose)\n",
    "        Split_Tree(split[\"right\"],cur_depth + 1,min_size = min_size,verbose= verbose)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can build the the whole tree by combining finding the first best split, and then splitting it until we can't do it anymore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Build_Tree(data,max_depth= 6,ratio = 10,target= \"left\",verbose = False):\n",
    "    root = Get_Best_Column_Split(data, verbose = verbose)\n",
    "    min_size = len(data) // ratio\n",
    "    Split_Tree(root,1,3,max_depth,verbose = verbose)\n",
    "    return root\n",
    "\n",
    "\n",
    "def Print_Tree(Node, depth=0):\n",
    "    if isinstance(Node, dict):\n",
    "        print('{} : {} {}'.format(depth, depth* ' ',Node['condition']))\n",
    "        Print_Tree(Node['left'], depth+1)\n",
    "        Print_Tree(Node['right'], depth+1)\n",
    "    else:\n",
    "        print('{} :{} {}'.format(depth, depth * ' ',Node))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now get the best decision tree for the HR dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  promotion_last_5years = 0\n",
      "1 :   Work_accident = 0\n",
      "2 :    satisfaction_level <= 0.81\n",
      "3 :    0\n",
      "3 :    0\n",
      "2 :    time_spend_company <= 2.0\n",
      "3 :    0\n",
      "3 :    0\n",
      "1 :   time_spend_company <= 5.0\n",
      "2 :    satisfaction_level <= 0.82\n",
      "3 :    0\n",
      "3 :    0\n",
      "2 :    satisfaction_level <= 0.5\n",
      "3 :    0\n",
      "3 :    0\n"
     ]
    }
   ],
   "source": [
    "tree = Build_Tree(HR,verbose = False)\n",
    "Print_Tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to predict using the resulting tree, we can traverse it just like we did with print, but this time we evaluate the conditions that have been established by the tree. Since we saved the conditions as a string, this means parsing the string to check the column and the comparison we must make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Parse_Value(value):\n",
    "    if \".\" in value:\n",
    "        return float(value)\n",
    "    try:\n",
    "        return int(value)\n",
    "    except:\n",
    "        return value\n",
    "\n",
    "def Predict(Node,row):\n",
    "    if isinstance(Node,dict):\n",
    "        condition = Node['condition'].split()\n",
    "        column = condition[0]\n",
    "        comparison = condition[1]\n",
    "        value = Parse_Value(condition[2])\n",
    "        \n",
    "        if comparison == \"=\":\n",
    "            if row[column] == value:\n",
    "                return Predict(Node['left'],row)\n",
    "            else:\n",
    "                return Predict(Node['right'],row)\n",
    "        else:\n",
    "            if row[column] <= value:\n",
    "                return Predict(Node['left'],row)\n",
    "            else:\n",
    "                return Predict(Node['right'],row)\n",
    "        \n",
    "    else:\n",
    "        return Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create a subsample of 10 rows from the dataset, and try to predict their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 1 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 1 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 1 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 1 Predicted: 0\n",
      "Expected: 1 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 1 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 1 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 1 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 1 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 1 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 1 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 1 Predicted: 0\n",
      "Accuracy = 76.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76000000000000001"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Test(sample,tree,target = \"left\", verbose = True):\n",
    "    total = 0\n",
    "    for index,row in sample.iterrows():\n",
    "        real = row[target]\n",
    "        prediction = Predict(tree,row)\n",
    "        if verbose:\n",
    "            print(\"Expected: \" + str(real) + \" Predicted: \" + str(prediction))\n",
    "        total += real == prediction\n",
    "    accuracy = total/len(sample)\n",
    "    if verbose:\n",
    "        print(\"Accuracy = {}%\".format(accuracy*100))\n",
    "    return accuracy\n",
    "    \n",
    "              \n",
    "np.random.seed(777)\n",
    "random_indexes = np.random.choice(len(HR), replace=False, size=50)\n",
    "sample = HR.iloc[random_indexes]\n",
    "Test(sample,tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you have probably taken notice now, our prediction are imbalanced. This is because the proportion of values of \"left\" in the HR dataset is imbalanced. Let's try to balance it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11428\n",
       "1     3571\n",
       "Name: left, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HR.left.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7142, 10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_dataset = HR.loc[HR.left == 0]\n",
    "random_left  = np.random.choice(len(left_dataset), replace=False, size=3571)\n",
    "sample_left = left_dataset.iloc[random_left]\n",
    "balanced = sample_left.append(HR.loc[HR.left == 1])\n",
    "balanced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's try retraining the tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  number_project <= 2.0\n",
      "1 :   average_montly_hours <= 136.0\n",
      "2 :    last_evaluation <= 0.48\n",
      "3 :    1\n",
      "3 :    1\n",
      "2 :    satisfaction_level <= 0.38\n",
      "3 :    1\n",
      "3 :    1\n",
      "1 :   time_spend_company <= 3.0\n",
      "2 :    Work_accident = 0\n",
      "3 :    0\n",
      "3 :    0\n",
      "2 :    satisfaction_level <= 0.11\n",
      "3 :    1\n",
      "3 :    1\n"
     ]
    }
   ],
   "source": [
    "btree = Build_Tree(balanced,max_depth = 5,ratio= 7,verbose = False)\n",
    "Print_Tree(btree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And once again, predict!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 1 Predicted: 1\n",
      "Expected: 0 Predicted: 1\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 1\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 0 Predicted: 1\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 1\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 0 Predicted: 0\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 1 Predicted: 1\n",
      "Expected: 0 Predicted: 1\n",
      "Accuracy = 90.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.90000000000000002"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_indexes = np.random.choice(len(balanced), replace=False, size=50)\n",
    "sample = balanced.iloc[random_indexes]\n",
    "Test(sample,btree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a much better accuracy. You have probably guessed that largely imbalanced datasets can throw off decision trees, as it will just throw whatever is most common. Do take care to not employ decision trees in problems like that, or at least change the way of predicting. In case we want to optimize the parameters, we can just create a function that does just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\juan9\\Anaconda3Fix\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   3092\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3093\u001b[0;31m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3094\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\juan9\\Anaconda3Fix\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mname\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\juan9\\Anaconda3Fix\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3076\u001b[0m                 name in self._accessors):\n\u001b[0;32m-> 3077\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3078\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute '_name'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-f7987fb37cca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mbest_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptimize_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-f7987fb37cca>\u001b[0m in \u001b[0;36mOptimize_tree\u001b[0;34m(train, test)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mratio\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mratios\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBuild_Tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mratio\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbest_accuracy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mbest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-f24d1312db87>\u001b[0m in \u001b[0;36mTest\u001b[0;34m(sample, tree, target, verbose)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mTest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"left\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mreal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\juan9\\Anaconda3Fix\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36miterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0mklass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\juan9\\Anaconda3Fix\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\juan9\\Anaconda3Fix\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   3093\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3094\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3095\u001b[0;31m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3096\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3097\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def Optimize_tree(train,test):\n",
    "    depths = list(range(1,10))\n",
    "    ratios= list(range(2,20))\n",
    "    best_accuracy = 0.0\n",
    "    best_params = {}\n",
    "    \n",
    "    for depth in depths:\n",
    "        for ratio in ratios:\n",
    "            tree = Build_Tree(train,max_depth = depth,ratio= ratio,verbose = False)\n",
    "            accuracy = Test(test,tree,verbose = False)\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_params[\"max_depth\"] = depth\n",
    "                best_params[\"ratio\"] = ratio\n",
    "                \n",
    "    print(best_accuracy)\n",
    "    return best_params\n",
    "\n",
    "shuffle  = balanced.sample(frac=1).reset_index(drop=True)\n",
    "train = shuffle[0:int(len(shuffle) * 0.2)]\n",
    "test = shuffle[len(train):len(shuffle)]\n",
    "best_params = Optimize_tree(train,test)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a large sample (about 600 samples instead of the 50 we were working with in the first test) the model gets an 81% accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees can also be used to predict numerical values. It follows almost the exact same procedure, but instead of using gini, we use the sum of squared errors. First, we define how to split the trees. This is done by using the **Standard Deviation Reduction** method. What this method does is that it compares the standard deviation of the target variable (in this case satisfaction level), against the standard deviation of both splits that are being made. This is done by calculating the difference between the whole standard deviation and the standard deviation of the split. Then, the split with the highest standard deviation difference is chosen.\n",
    "\n",
    "$SDR(y,x) = SD(y) - SD(y,x)$ Where $SD$ = Standard Deviation\n",
    "\n",
    "Example:\n",
    "\n",
    "$SDR(Satisfaction level,last evaluation) = SD(Satisfaction level) - SD(Satisfaction level,last evaluation) $\n",
    "\n",
    "**Why?** Because this means that this split is the most homogeneous one, or in more simple terms, there's enough difference between the whole and the split ( the standard deviation of the split is small, so the difference is a large number), that the split contains information that separates it well from the whole, and thus is good for predictions. This is similar to calculating the Gini index, where we wanted splits with imbalanced proportions as they tell more information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SdevReduction(groups,sdev,target_name = \"satisfaction_level\"):\n",
    "    best_sdev = 0\n",
    "    best_group = None\n",
    "    for group in groups:\n",
    "        groupsdev = group[target_name].std()\n",
    "        diff = sdev - groupsdev\n",
    "        if diff > best_sdev:\n",
    "            best_sdev = diff\n",
    "            best_group = group\n",
    "            \n",
    "    return best_sdev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a modification of getting the best column split. The only difference here is that instead of calculating Gini, we calculate the SDR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Get_Best_Column_Reg(data,target=\"satisfaction_level\",verbose = False):\n",
    "    temp = data.drop(target, axis = 1).copy()\n",
    "    best_sdev = 0\n",
    "    best_split_condition = \"\"\n",
    "    best_split = {}\n",
    "    orig_sdev = data[target].std()\n",
    "    for column in temp.columns:\n",
    "        column_splits = Create_Split(data,column)\n",
    "        for split in column_splits:\n",
    "            split_sdev = SdevReduction(split[0:2],orig_sdev)\n",
    "            if verbose:\n",
    "                print(\"Splitting : \" + split[2] + \" SDEV : \" + str(split_sdev))\n",
    "            if split_sdev > best_sdev:\n",
    "                best_sdev = split_sdev\n",
    "                best_split_condition = split[2]\n",
    "                best_split[\"left\"] = split[0].drop(column,axis = 1)\n",
    "                best_split[\"right\"] = split[1].drop(column, axis = 1)\n",
    "                best_split[\"condition\"] = best_split_condition\n",
    "                \n",
    "    if verbose:\n",
    "        print(\"Best split: \" + best_split_condition + \" best SDEV: \" + str(best_sdev))\n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting : last_evaluation <= 0.56 SDEV : 0.039633242794188644\n",
      "Splitting : last_evaluation <= 0.72 SDEV : 0.02816914778615326\n",
      "Splitting : last_evaluation <= 0.87 SDEV : 0.008339809840993945\n",
      "Splitting : number_project <= 3.0 SDEV : 0.040077096467931506\n",
      "Splitting : number_project <= 4.0 SDEV : 0.038811722043194496\n",
      "Splitting : number_project <= 5.0 SDEV : 0.033203599557505015\n",
      "Splitting : average_montly_hours <= 156.0 SDEV : 0.037954194101917665\n",
      "Splitting : average_montly_hours <= 200.0 SDEV : 0.02867664792861066\n",
      "Splitting : average_montly_hours <= 245.0 SDEV : 0.026187545625358938\n",
      "Splitting : time_spend_company <= 3.0 SDEV : 0.04547947471900213\n",
      "Splitting : time_spend_company <= 4.0 SDEV : 0.005282887851238843\n",
      "Splitting : Work_accident = 0 SDEV : 0.017442455075225904\n",
      "Splitting : left = 1 SDEV : 0.03152689654142121\n",
      "Splitting : promotion_last_5years = 0 SDEV : 0.036141332889753935\n",
      "Splitting : dept = sales SDEV : 0.0006116703413255042\n",
      "Splitting : salary = low SDEV : 0.006357049903122081\n",
      "Best split: time_spend_company <= 3.0 best SDEV: 0.04547947471900213\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>dept</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.77</td>\n",
       "      <td>6</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5</td>\n",
       "      <td>259</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "1                0.80             0.86               5                   262   \n",
       "2                0.11             0.88               7                   272   \n",
       "3                0.72             0.87               5                   223   \n",
       "6                0.10             0.77               6                   247   \n",
       "7                0.92             0.85               5                   259   \n",
       "\n",
       "   Work_accident  left  promotion_last_5years   dept  salary  \n",
       "1              0     1                      0  sales  medium  \n",
       "2              0     1                      0  sales  medium  \n",
       "3              0     1                      0  sales     low  \n",
       "6              0     1                      0  sales     low  \n",
       "7              0     1                      0  sales     low  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Best_Split = Get_Best_Column_Reg(HR,\"satisfaction_level\",verbose = True)\n",
    "Best_Split[\"right\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we also modify the terminal nodes and recursive splitting. For the terminal nodes, instead of returning the most common value in the in the split, we return the mean of the target value in the split. This is  how decision trees do predictions for regression. For the recursive splitting, we just replace the appropriate functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def terminal_reg(group,target=\"satisfaction_level\"):\n",
    "    return group[target].mean()\n",
    "\n",
    "def Reg_Split(split,cur_depth,min_size,max_depth=3,target = \"satisfaction_level\",verbose = False):\n",
    "    left,right = split[\"left\"],split[\"right\"]\n",
    "    #In case our depth is too large.\n",
    "    del split[\"left\"]\n",
    "    del split[\"right\"]\n",
    "    \n",
    "    \n",
    "    if  not left.any or  not right.any:\n",
    "        split[\"left\"] = split[\"right\"] = terminal_reg((left + right))\n",
    "        return\n",
    "    if cur_depth == max_depth:\n",
    "        split[\"left\"], split[\"right\"] = terminal_reg(left), terminal_reg(right)\n",
    "        return\n",
    "    #Calculate left\n",
    "    if len(left) <= min_size:\n",
    "        split[\"left\"] = terminal_reg(left)\n",
    "    else:\n",
    "        split[\"left\"] = Get_Best_Column_Reg(left,verbose = verbose)\n",
    "        Reg_Split(split[\"left\"],cur_depth + 1,min_size=min_size,verbose = verbose)\n",
    "    \n",
    "    #Calculate right\n",
    "    if len(right) <= min_size:\n",
    "        split[\"right\"] = terminal_reg(right)\n",
    "    else:\n",
    "        split[\"right\"] = Get_Best_Column_Reg(right,verbose = verbose)\n",
    "        Reg_Split(split[\"right\"],cur_depth + 1,min_size = min_size,verbose= verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the regression tree building, the same thing is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Build_Reg_Tree(data,max_depth= 3,ratio = 10,target= \"satisfaction_level\",verbose = False):\n",
    "    root = Get_Best_Column_Reg(data, verbose = verbose)\n",
    "    min_size = len(data) // ratio\n",
    "    Reg_Split(root,1,min_size,max_depth,verbose = verbose)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  time_spend_company <= 3.0\n",
      "1 :   left = 1\n",
      "2 :    last_evaluation <= 0.51\n",
      "3 :    0.40774038461538414\n",
      "3 :    0.4230855018587355\n",
      "2 :    number_project <= 4.0\n",
      "3 :    0.7016313264200547\n",
      "3 :    0.6822621298046635\n",
      "1 :   number_project <= 5.0\n",
      "2 :    left = 1\n",
      "3 :    0.7525047801147224\n",
      "3 :    0.60905449770191\n",
      "2 :   0.20731967213114882\n"
     ]
    }
   ],
   "source": [
    "reg_tree = Build_Reg_Tree(HR,max_depth = 5,verbose = False)\n",
    "Print_Tree(reg_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 0.74 Predicted: 0.6822621298046635\n",
      "Expected: 0.37 Predicted: 0.6822621298046635\n",
      "Expected: 0.71 Predicted: 0.7016313264200547\n",
      "Expected: 0.91 Predicted: 0.7016313264200547\n",
      "Expected: 0.44 Predicted: 0.6822621298046635\n",
      "Expected: 0.54 Predicted: 0.7016313264200547\n",
      "Expected: 0.59 Predicted: 0.60905449770191\n",
      "Expected: 0.39 Predicted: 0.40774038461538414\n",
      "Expected: 0.67 Predicted: 0.6822621298046635\n",
      "Expected: 0.11 Predicted: 0.20731967213114882\n",
      "Expected: 0.74 Predicted: 0.7016313264200547\n",
      "Expected: 0.73 Predicted: 0.60905449770191\n",
      "Expected: 0.36 Predicted: 0.40774038461538414\n",
      "Expected: 0.5 Predicted: 0.7016313264200547\n",
      "Expected: 0.66 Predicted: 0.7016313264200547\n",
      "Expected: 0.62 Predicted: 0.60905449770191\n",
      "Expected: 0.99 Predicted: 0.6822621298046635\n",
      "Expected: 0.5 Predicted: 0.6822621298046635\n",
      "Expected: 0.1 Predicted: 0.20731967213114882\n",
      "Expected: 0.11 Predicted: 0.20731967213114882\n",
      "Expected: 0.71 Predicted: 0.7016313264200547\n",
      "Expected: 0.15 Predicted: 0.60905449770191\n",
      "Expected: 0.89 Predicted: 0.6822621298046635\n",
      "Expected: 0.09 Predicted: 0.20731967213114882\n",
      "Expected: 0.54 Predicted: 0.7016313264200547\n",
      "Expected: 0.8 Predicted: 0.7016313264200547\n",
      "Expected: 0.67 Predicted: 0.7016313264200547\n",
      "Expected: 0.97 Predicted: 0.7016313264200547\n",
      "Expected: 0.6 Predicted: 0.7016313264200547\n",
      "Expected: 0.97 Predicted: 0.7016313264200547\n",
      "Expected: 0.59 Predicted: 0.7016313264200547\n",
      "Expected: 0.55 Predicted: 0.60905449770191\n",
      "Expected: 0.38 Predicted: 0.40774038461538414\n",
      "Expected: 0.51 Predicted: 0.7525047801147224\n",
      "Expected: 0.46 Predicted: 0.40774038461538414\n",
      "Expected: 0.6 Predicted: 0.7016313264200547\n",
      "Expected: 0.82 Predicted: 0.7016313264200547\n",
      "Expected: 0.48 Predicted: 0.7016313264200547\n",
      "Expected: 0.38 Predicted: 0.40774038461538414\n",
      "Expected: 0.11 Predicted: 0.20731967213114882\n",
      "Expected: 0.77 Predicted: 0.60905449770191\n",
      "Expected: 0.28 Predicted: 0.7016313264200547\n",
      "Expected: 0.94 Predicted: 0.7016313264200547\n",
      "Expected: 0.61 Predicted: 0.6822621298046635\n",
      "Expected: 0.9 Predicted: 0.7016313264200547\n",
      "Expected: 0.91 Predicted: 0.6822621298046635\n",
      "Expected: 0.64 Predicted: 0.7016313264200547\n",
      "Expected: 0.9 Predicted: 0.7016313264200547\n",
      "Expected: 0.31 Predicted: 0.60905449770191\n",
      "Expected: 0.43 Predicted: 0.4230855018587355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17661582966442524"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Reg_Test(sample,tree,target = \"satisfaction_level\", verbose = True):\n",
    "    error = 0\n",
    "    for index,row in sample.iterrows():\n",
    "        real = row[target]\n",
    "        prediction = Predict(tree,row)\n",
    "        if verbose:\n",
    "            print(\"Expected: \" + str(real) + \" Predicted: \" + str(prediction))\n",
    "        error += (real - prediction) ** 2\n",
    "    MSE  = error/len(sample)\n",
    "    RMSE = pow(MSE,0.5)\n",
    "    return RMSE\n",
    "    \n",
    "              \n",
    "random_indexes = np.random.choice(len(HR), replace=False, size=50)\n",
    "sample = HR.iloc[random_indexes]\n",
    "Reg_Test(sample,reg_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1947695750872891"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = HR.sample(frac = 0.2)\n",
    "Reg_Test(sample,reg_tree,verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there we go. We now know how to create Decision trees for Regression and Classification problems. Still, Decision trees are hard to apply to some datasets, as they are easily swayed. On the next notebook, we'll see how to combine several trees into a more robust model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
